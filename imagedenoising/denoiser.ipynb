{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from skimage.util import random_noise\n",
    "import cv2\n",
    "from torchvision.transforms import ToTensor\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add noise, using skimage's random_noise function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "from skimage.util import random_noise\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NoisyImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.dataset = ImageFolder(root_dir, transform=transform)\n",
    "        self.transform = transform\n",
    "\n",
    "    def add_noise(self, image):\n",
    "        noise_type = np.random.choice(['gaussian', 'salt', 'pepper', 'speckle'])\n",
    "        if noise_type == 'gaussian':\n",
    "            noisy_img = random_noise(image, mode='gaussian', var=0.01)\n",
    "        elif noise_type == 'salt':\n",
    "            noisy_img = random_noise(image, mode='salt', amount=0.02)\n",
    "        elif noise_type == 'pepper':\n",
    "            noisy_img = random_noise(image, mode='pepper', amount=0.02)\n",
    "        elif noise_type == 'speckle':\n",
    "            noisy_img = random_noise(image, mode='speckle', var=0.01)\n",
    "        return np.clip(noisy_img, 0, 1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path, _ = self.dataset.samples[index]\n",
    "        filename = os.path.basename(path)\n",
    "        clean_img, _ = self.dataset[index]\n",
    "        noisy_img = self.add_noise(clean_img.numpy().transpose(1, 2, 0))\n",
    "        noisy_img = torch.tensor(noisy_img.transpose(2, 0, 1)).float()\n",
    "        return noisy_img, clean_img, filename\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define denoising model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipDenoisingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SkipDenoisingModel, self).__init__()\n",
    "        \n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "    )\n",
    "        self.encoder3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.encoder4 = nn.Sequential(\n",
    "            nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.decoder4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 8, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 16, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16, 32, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(64, 3, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # encode\n",
    "        x = self.encoder1(x)\n",
    "        x = self.pool(x)\n",
    "        enc2 = self.encoder2(x)\n",
    "        x = self.pool(enc2)\n",
    "        enc3 = self.encoder3(x)\n",
    "        x = self.pool(enc3)\n",
    "        enc4 = self.encoder4(x) \n",
    "\n",
    "        x = self.pool(enc4)\n",
    "        # decode\n",
    "        x = self.decoder4(x)\n",
    "        x = enc4 + x                                                        \n",
    "        x = self.decoder3(x)\n",
    "        x = enc3 + x\n",
    "        x = self.decoder2(x)\n",
    "        x = enc2 + x\n",
    "        x = self.decoder1(x)\n",
    "        x = self.final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_results(original, noisy, denoised, index=0, filename=None):\n",
    "    \"\"\"\n",
    "    Visualize the original, noisy, and denoised images side by side.\n",
    "    Optionally, display the filename.\n",
    "    \"\"\"\n",
    "    original_img = original[index].detach().cpu().permute(1, 2, 0).numpy()\n",
    "    noisy_img = noisy[index].detach().cpu().permute(1, 2, 0).numpy()\n",
    "    denoised_img = denoised[index].detach().cpu().permute(1, 2, 0).numpy()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig.suptitle(f\"Image: {filename if filename else 'N/A'}\", fontsize=16)\n",
    "\n",
    "    axs[0].imshow(original_img)\n",
    "    axs[0].set_title('Original')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(noisy_img)\n",
    "    axs[1].set_title('Noisy')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    axs[2].imshow(denoised_img)\n",
    "    axs[2].set_title('Denoised')\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model function, visualize every 500 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, num_epochs=20):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_history = []\n",
    "    ssim_history = []\n",
    "    psnr_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_sample_count = 0\n",
    "        running_loss = 0.0\n",
    "        total_psnr = 0.0\n",
    "        total_ssim = 0.0\n",
    "        \n",
    "        for i, (noisy_imgs, clean_imgs, filenames) in enumerate(dataloader):\n",
    "            running_sample_count += len(noisy_imgs)\n",
    "            batch_psnr = 0.0\n",
    "            batch_ssim = 0.0\n",
    "            batch_size = noisy_imgs.size(0)\n",
    "            noisy_imgs, clean_imgs = noisy_imgs.to(\"mps\"), clean_imgs.to(\"mps\")\n",
    "            \n",
    "            outputs = model(noisy_imgs)\n",
    "            loss = criterion(outputs, clean_imgs)\n",
    "            # print(f\"shape of clean imgs: {clean_imgs.shape}\")\n",
    "            # print(f\"shape of noisy imgs: {noisy_imgs.size(0)}\")\n",
    "            \n",
    "            for j in range(len(noisy_imgs)):\n",
    "                psnr = peak_signal_noise_ratio(\n",
    "                    clean_imgs[j].cpu().detach().numpy(),\n",
    "                    outputs[j].cpu().detach().numpy(),\n",
    "                    data_range=1.0 \n",
    "                    )\n",
    "                ssim = structural_similarity(\n",
    "                    clean_imgs[j].cpu().detach().numpy().transpose(1, 2, 0),\n",
    "                    outputs[j].cpu().detach().numpy().transpose(1, 2, 0),\n",
    "                    win_size=7,\n",
    "                    channel_axis=-1,\n",
    "                    data_range=1.0\n",
    "                )\n",
    "                \n",
    "                batch_psnr += psnr\n",
    "                batch_ssim += ssim \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            \n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            total_ssim += batch_ssim\n",
    "            total_psnr += batch_psnr\n",
    "            \n",
    "            batch_ssim /= batch_size\n",
    "            batch_psnr /= batch_size\n",
    "\n",
    "            # Visualize every 500 batches\n",
    "            if i % 125 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i}/{len(dataloader)}], Loss: {loss.item():.4f}, SSIM: {batch_ssim:.4f}, PSNR: {batch_psnr:.4f}\")\n",
    "                visualize_results(clean_imgs, noisy_imgs, outputs.detach(), index=0, filename=filenames[0])\n",
    "        avg_loss = running_loss / len(dataloader)\n",
    "        avg_ssim = total_ssim / running_sample_count\n",
    "        avg_psnr = total_psnr / running_sample_count\n",
    "        loss_history.append(avg_loss)\n",
    "        ssim_history.append(avg_ssim)\n",
    "        psnr_history.append(avg_psnr)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] completed. Average Loss: {avg_loss:.4f}. Average SSIM: {avg_ssim:.4f}. Average PSNR: {avg_psnr:.4f}\")\n",
    "    \n",
    "    print(\"Training complete\")\n",
    "    return model, loss_history, ssim_history, psnr_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(model, dataloader, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a given dataloader and compute PSNR and SSIM metrics.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    psnr_total = 0\n",
    "    ssim_total = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for noisy_imgs, clean_imgs, filenames in dataloader:\n",
    "            noisy_imgs, clean_imgs = noisy_imgs.to(device), clean_imgs.to(device)\n",
    "            \n",
    "            outputs = model(noisy_imgs)\n",
    "            \n",
    "            batch_psnr = 0\n",
    "            batch_ssim = 0\n",
    "\n",
    "            # Compute PSNR and SSIM for each image in the batch\n",
    "            for i in range(len(noisy_imgs)):\n",
    "                psnr = peak_signal_noise_ratio(\n",
    "                    clean_imgs[i].cpu().numpy(),\n",
    "                    outputs[i].cpu().numpy(),\n",
    "                    data_range=1.0 \n",
    "                )\n",
    "                ssim = structural_similarity(\n",
    "                    clean_imgs[i].cpu().numpy().transpose(1, 2, 0),\n",
    "                    outputs[i].cpu().numpy().transpose(1, 2, 0),\n",
    "                    win_size=7,\n",
    "                    channel_axis=-1,\n",
    "                    data_range=1.0\n",
    "                )\n",
    "                \n",
    "                batch_psnr += psnr\n",
    "                batch_ssim += ssim\n",
    "                print(f\"Filename: {filenames[i]}, PSNR: {psnr:.4f}, SSIM: {ssim:.4f}\")\n",
    "            \n",
    "            psnr_total += batch_psnr / len(noisy_imgs)\n",
    "            ssim_total += batch_ssim / len(noisy_imgs)\n",
    "            num_batches += 1\n",
    "\n",
    "            break\n",
    "\n",
    "    avg_psnr = psnr_total / num_batches\n",
    "    avg_ssim = ssim_total / num_batches\n",
    "    print(f\"Average PSNR: {avg_psnr:.4f}, Average SSIM: {avg_ssim:.4f}\")\n",
    "\n",
    "    return avg_psnr, avg_ssim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = NoisyImageDataset(root_dir='Deep-Learning-Data', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = SkipDenoisingModel().to(\"mps\")\n",
    "trained_model, loss_history, ssim_history, psnr_history = train_model(model, dataloader, num_epochs=20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(trained_model, dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(loss_history)):\n",
    "    print(f\"Averages after training epochs {i+1}: Average Loss: {loss_history[i]:.5f}, Average SSIM: {ssim_history[i]:.4f}, Average PSNR: {psnr_history[i]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(loss_history))\n",
    "print(len(ssim_history))\n",
    "print(len(psnr_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
